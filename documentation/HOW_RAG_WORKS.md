# ğŸ” How HÃ¥faGPT's RAG System Works

> A beginner-friendly guide to understanding HÃ¥faGPT's Retrieval-Augmented Generation system.

---

## ğŸ“– What is RAG?

**RAG = Retrieval-Augmented Generation**

Instead of the AI making up answers, RAG:
1. **Retrieves** relevant information from a knowledge base
2. **Augments** the prompt with that information
3. **Generates** an answer based on real sources

Think of it like giving the AI a cheat sheet before answering each question.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           HÃ¥faGPT ARCHITECTURE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     USER                    FRONTEND                      BACKEND
   â”Œâ”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ğŸ’¬   â”‚    HTTPS      â”‚  React +  â”‚    API        â”‚   FastAPI    â”‚
   â”‚ User â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Vite     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Python     â”‚
   â”‚      â”‚               â”‚           â”‚               â”‚              â”‚
   â””â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                        â”‚                â”‚
                    â–¼                                        â–¼                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  PostgreSQL  â”‚                        â”‚   OpenAI     â”‚  â”‚    OpenAI    â”‚
            â”‚  + PGVector  â”‚                        â”‚  Embeddings  â”‚  â”‚   GPT-4o     â”‚
            â”‚              â”‚                        â”‚              â”‚  â”‚    mini      â”‚
            â”‚ 45,183 chunksâ”‚                        â”‚ text-embed-  â”‚  â”‚              â”‚
            â”‚              â”‚                        â”‚ ding-3-small â”‚  â”‚              â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   KNOWLEDGE BASE  â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ ğŸ“• Dictionaries   â”‚
        â”‚ ğŸ“– Grammar Books  â”‚
        â”‚ ğŸŒ Guampedia      â”‚
        â”‚ ğŸ“ Lengguahi-ta   â”‚
        â”‚ ğŸ“° News Articles  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ The RAG Flow (Step by Step)

When a user asks: **"What does 'maolek' mean?"**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: USER SENDS MESSAGE                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   User types: "What does 'maolek' mean?"                               â”‚
â”‚                        â”‚                                                â”‚
â”‚                        â–¼                                                â”‚
â”‚   Frontend sends POST /api/chat                                         â”‚
â”‚   Body: { "message": "What does 'maolek' mean?", "mode": "english" }   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: QUERY TYPE DETECTION                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: detect_query_type(query)                                    â”‚
â”‚   File: src/rag/chamorro_rag.py                                         â”‚
â”‚                                                                         â”‚
â”‚   Checks if query is:                                                   â”‚
â”‚   â€¢ "lookup" â†’ "What does X mean?" â†’ Boost dictionaries                â”‚
â”‚   â€¢ "educational" â†’ "How do I say...?" â†’ Boost lessons                 â”‚
â”‚   â€¢ "general" â†’ Normal RAG                                              â”‚
â”‚                                                                         â”‚
â”‚   Result: "lookup" âœ“                                                    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: CHARACTER NORMALIZATION                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: normalize_chamorro_text(query)                              â”‚
â”‚   File: src/rag/chamorro_rag.py                                         â”‚
â”‚                                                                         â”‚
â”‚   Handles Chamorro spelling variations:                                 â”‚
â”‚   â€¢ "HÃ¥fa Adai" â†’ "hafa adai"                                          â”‚
â”‚   â€¢ "MaÃ±ana Si Yu'os" â†’ "manana si yuos"                               â”‚
â”‚   â€¢ Removes accents: Ã¥â†’a, Ã±â†’n, glottal stops removed                   â”‚
â”‚                                                                         â”‚
â”‚   Why? Users might type "hafa" or "HÃ¥fa" - both should match!          â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: KEYWORD SEARCH (Fast Path)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: _keyword_search_dictionaries(target_word)                   â”‚
â”‚   File: src/rag/chamorro_rag.py                                         â”‚
â”‚                                                                         â”‚
â”‚   For "lookup" queries, try SQL keyword search FIRST:                   â”‚
â”‚                                                                         â”‚
â”‚   SELECT document FROM langchain_pg_embedding                           â”‚
â”‚   WHERE document ILIKE '**maolek**%'  -- Exact headword match          â”‚
â”‚   AND source LIKE '%dictionary%'                                        â”‚
â”‚   ORDER BY priority                                                     â”‚
â”‚   LIMIT 3;                                                              â”‚
â”‚                                                                         â”‚
â”‚   If found â†’ Skip semantic search (faster!)                             â”‚
â”‚   If not found â†’ Fall through to semantic search                        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: SEMANTIC SEARCH (Vector Similarity)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: vectorstore.similarity_search(query, k=30)                  â”‚
â”‚   File: src/rag/chamorro_rag.py                                         â”‚
â”‚                                                                         â”‚
â”‚   1. Convert query to embedding vector (384 dimensions)                 â”‚
â”‚      "What does maolek mean?" â†’ [0.023, -0.156, 0.089, ...]            â”‚
â”‚                                                                         â”‚
â”‚   2. Find similar vectors in PGVector database                          â”‚
â”‚      Uses cosine similarity to find semantically similar chunks         â”‚
â”‚                                                                         â”‚
â”‚   3. Return top 30 candidates (we'll re-rank them next)                 â”‚
â”‚                                                                         â”‚
â”‚   Why 30? We get more candidates for better re-ranking.                 â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: RE-RANKING WITH SOURCE PRIORITY                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: _search_impl() scoring logic                                â”‚
â”‚   File: src/rag/chamorro_rag.py                                         â”‚
â”‚                                                                         â”‚
â”‚   Each chunk gets a score based on:                                     â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚  SOURCE PRIORITY TIERS                                     â”‚        â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚   â”‚  Priority 115: Lengguahi-ta lessons â†’ 3x boost            â”‚        â”‚
â”‚   â”‚  Priority 110: PDN bilingual articles â†’ 3x boost          â”‚        â”‚
â”‚   â”‚  Priority 100: Guampedia, grammar â†’ 2x boost              â”‚        â”‚
â”‚   â”‚  Priority 50:  Dictionaries â†’ 1x (normal)                 â”‚        â”‚
â”‚   â”‚  Priority -50: 1865 archival â†’ 0.5x penalty               â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                         â”‚
â”‚   PLUS query-type boost:                                                â”‚
â”‚   â€¢ "lookup" query â†’ Dictionaries get 10x boost!                        â”‚
â”‚   â€¢ "educational" query â†’ Lessons get 1.5x boost                        â”‚
â”‚                                                                         â”‚
â”‚   Result: Top 3 chunks selected after re-ranking                        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 7: CREATE CONTEXT STRING                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: create_context(query, k=3)                                  â”‚
â”‚   File: src/rag/chamorro_rag.py                                         â”‚
â”‚                                                                         â”‚
â”‚   Combines the 3 best chunks into one context string:                   â”‚
â”‚                                                                         â”‚
â”‚   """                                                                   â”‚
â”‚   Source: Revised Chamorro Dictionary                                   â”‚
â”‚   **maolek**                                                            â”‚
â”‚   (adj.) good, well, fine, okay                                         â”‚
â”‚   Example: Kao maolek hao? - Are you okay?                              â”‚
â”‚                                                                         â”‚
â”‚   Source: Lengguahi-ta Lessons                                          â”‚
â”‚   Maolek is one of the most common Chamorro words...                    â”‚
â”‚   """                                                                   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 8: AUGMENT PROMPT & GENERATE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Function: get_chatbot_response()                                      â”‚
â”‚   File: api/chatbot_service.py                                          â”‚
â”‚                                                                         â”‚
â”‚   Build the final prompt for GPT-4o-mini:                               â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚  SYSTEM: You are HÃ¥faGPT, a Chamorro language tutor...    â”‚        â”‚
â”‚   â”‚                                                            â”‚        â”‚
â”‚   â”‚  CONTEXT FROM KNOWLEDGE BASE:                              â”‚        â”‚
â”‚   â”‚  [The 3 chunks we retrieved]                               â”‚        â”‚
â”‚   â”‚                                                            â”‚        â”‚
â”‚   â”‚  USER: What does 'maolek' mean?                           â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                         â”‚
â”‚   OpenAI API call:                                                      â”‚
â”‚   response = openai.chat.completions.create(                            â”‚
â”‚       model="gpt-4o-mini",                                              â”‚
â”‚       messages=[system, context, user_message]                          â”‚
â”‚   )                                                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 9: RETURN RESPONSE WITH SOURCES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Response sent back to user:                                           â”‚
â”‚                                                                         â”‚
â”‚   {                                                                     â”‚
â”‚     "response": "**Maolek** means 'good', 'well', or 'okay'...",       â”‚
â”‚     "sources": [                                                        â”‚
â”‚       { "name": "Revised Chamorro Dictionary", "priority": 50 },        â”‚
â”‚       { "name": "Lengguahi-ta Lessons", "priority": 115 }               â”‚
â”‚     ],                                                                  â”‚
â”‚     "mode": "english",                                                  â”‚
â”‚     "response_time_ms": 2340                                            â”‚
â”‚   }                                                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Key Files

| File | Purpose |
|------|---------|
| `api/chatbot_service.py` | Main entry point - handles chat requests, calls RAG |
| `src/rag/chamorro_rag.py` | **Core RAG logic** - search, re-ranking, context creation |
| `src/rag/manage_rag_db.py` | Document ingestion - add PDFs, websites to database |
| `api/dictionary_service.py` | Dictionary API - vocabulary, flashcards, quizzes |
| `src/utils/improved_chunker.py` | Token-aware text chunking |

### Where the Magic Happens

**`src/rag/chamorro_rag.py`** - This is the heart of the RAG system:

```python
class ChamorroRAG:
    def __init__(self):
        # Connect to PostgreSQL + PGVector
        self.vectorstore = PGVector(
            embeddings=OpenAIEmbeddings(model="text-embedding-3-small"),
            collection_name="chamorro_grammar",
            connection=DATABASE_URL
        )
    
    def search(self, query, k=3):
        # 1. Normalize query (handle accents, glottal stops)
        normalized = normalize_chamorro_text(query)
        
        # 2. Detect query type (lookup vs educational)
        query_type = detect_query_type(query)
        
        # 3. Try keyword search first (fast path)
        if query_type == 'lookup':
            keyword_results = self._keyword_search_dictionaries(query)
            if keyword_results:
                return keyword_results
        
        # 4. Semantic search (vector similarity)
        results = self.vectorstore.similarity_search(query, k=30)
        
        # 5. Re-rank by source priority
        scored = self._apply_source_boosting(results, query_type)
        
        # 6. Return top k
        return scored[:k]
    
    def create_context(self, query, k=3):
        # Search and format results into context string
        chunks = self.search(query, k)
        context = "\n\n".join([format_chunk(c) for c in chunks])
        return context, sources
```

---

## ğŸ”„ Hybrid Search: Why Both Keyword AND Semantic?

### The Problem with Pure Semantic Search

Semantic search is great for finding **similar meaning**:
- Query: "How do I say goodbye?" 
- Finds: "Adios" (different words, same meaning) âœ…

But it can fail for **exact lookups**:
- Query: "What does 'maolek' mean?"
- Might return: Random sentences containing "maolek" 
- Instead of: The dictionary definition âŒ

### Our Solution: Hybrid Search

```
User Query: "What does 'maolek' mean?"
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Extract target word  â”‚  â†’ "maolek"
        â”‚  (if it's a lookup)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  SQL Keyword Search   â”‚  â†’ SELECT * FROM chunks
        â”‚  (exact headword)     â”‚     WHERE content LIKE '**maolek**%'
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
           Found?   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ YES       â”‚           â”‚ NO
        â–¼           â”‚           â–¼
   Return          â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   Dictionary      â”‚      â”‚  Semantic Search      â”‚
   Entry! ğŸ¯       â”‚      â”‚  (vector similarity)  â”‚
                   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                  â”‚
                   â”‚                  â–¼
                   â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚      â”‚  Re-rank by source    â”‚
                   â”‚      â”‚  priority             â”‚
                   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                  â”‚
                   â”‚                  â–¼
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   Return top 3 chunks
```

**Result:**
- "What does X mean?" â†’ Dictionary entry (fast, accurate)
- "How do I greet someone?" â†’ Lessons with context (semantic + boosted)

---

## ğŸ“Š Comparison: HÃ¥faGPT vs. Basic Pinecone RAG

| Feature | Basic Pinecone (Beginner) | HÃ¥faGPT (Production) |
|---------|---------------------------|----------------------|
| **Vector DB** | Pinecone (managed) | PostgreSQL + PGVector (self-hosted) |
| **Embeddings** | Auto-generated | OpenAI text-embedding-3-small |
| **Search** | Pure semantic | Hybrid (keyword + semantic) |
| **Ranking** | By similarity only | By similarity + source priority |
| **Query Detection** | âŒ None | âœ… lookup/educational/general |
| **Character Handling** | âŒ None | âœ… Chamorro normalization |
| **Cost** | $70+/month at scale | ~$0.30/month (OpenAI embeddings) |
| **Control** | Limited | Full (SQL, custom logic) |

### Same Core Concepts!

Both systems follow the same pattern:

```
1. CHUNK documents into pieces
2. EMBED chunks as vectors
3. STORE in vector database
4. SEARCH by similarity
5. AUGMENT prompt with results
6. GENERATE response with LLM
```

HÃ¥faGPT just adds more layers for production quality:
- **Keyword search** for exact matches
- **Source boosting** for content quality
- **Query detection** for intent-based retrieval
- **Character normalization** for language-specific handling

---

## ğŸ§® The Math: How Vector Similarity Works

### What is an Embedding?

An embedding converts text into a list of numbers (a vector) that captures meaning:

```
"good" â†’ [0.23, -0.15, 0.89, 0.02, ...]  (384 dimensions)
"well" â†’ [0.21, -0.14, 0.91, 0.01, ...]  (similar numbers!)
"bad"  â†’ [-0.45, 0.32, -0.67, 0.15, ...] (different numbers)
```

### Cosine Similarity

To find similar chunks, we calculate how "close" two vectors are:

```
similarity = cos(Î¸) = (A Â· B) / (|A| Ã— |B|)

Result: 0.0 = completely different
        1.0 = identical meaning
```

Example:
```
Query: "What does 'good' mean?"
Query embedding: [0.23, -0.15, 0.89, ...]

Chunk 1: "Maolek means good, well, fine"
Embedding: [0.22, -0.14, 0.88, ...]
Similarity: 0.97 âœ… HIGH MATCH!

Chunk 2: "The weather in Guam is tropical"
Embedding: [0.56, 0.23, -0.34, ...]
Similarity: 0.12 âŒ LOW MATCH
```

### Why 384 Dimensions?

- More dimensions = more nuance captured
- OpenAI's `text-embedding-3-small` uses 384 (good balance)
- Larger models use 1536+ (overkill for our use case)

---

## ğŸ’¾ Database Structure

### PGVector Table

```sql
-- The main embeddings table (created by LangChain)
CREATE TABLE langchain_pg_embedding (
    id UUID PRIMARY KEY,
    collection_id UUID,           -- Links to collection
    document TEXT,                -- The actual chunk text
    embedding VECTOR(384),        -- The 384-dimension vector
    cmetadata JSONB               -- Metadata (source, priority, etc.)
);

-- Example metadata stored in cmetadata:
{
    "source": "Revised Chamorro Dictionary",
    "era_priority": 50,
    "source_type": "dictionary",
    "chunk_index": 1234
}
```

### How Search Works (Under the Hood)

```sql
-- Find 30 most similar chunks
SELECT document, cmetadata,
       1 - (embedding <=> query_embedding) AS similarity
FROM langchain_pg_embedding
WHERE collection_id = 'chamorro_grammar'
ORDER BY embedding <=> query_embedding  -- <=> is cosine distance
LIMIT 30;
```

---

## ğŸ“ˆ Performance Characteristics

| Metric | Value |
|--------|-------|
| Total chunks | 45,183 |
| Embedding dimensions | 384 |
| Avg chunk size | 350 tokens |
| Search latency | ~200-400ms |
| Total response time | 2-8 seconds |
| Cost per query | ~$0.0001 (embedding) + ~$0.001 (GPT-4o-mini) |

### Why It's Fast

1. **PGVector indexes** - Uses IVFFlat or HNSW for fast approximate search
2. **Hybrid search** - Keyword search bypasses embeddings for lookups
3. **Limited k** - Only retrieve 3 chunks, not 100
4. **GPT-4o-mini** - Faster than GPT-4

---

## ğŸ“ Summary

### The RAG Pattern (Universal)

```
1. CHUNK your documents (350 tokens each)
2. EMBED chunks into vectors (OpenAI or HuggingFace)
3. STORE in vector database (PGVector, Pinecone, etc.)
4. When user asks a question:
   a. EMBED the question
   b. SEARCH for similar chunks
   c. AUGMENT the prompt with retrieved chunks
   d. GENERATE response with LLM
```

### What Makes HÃ¥faGPT Production-Grade

1. **Hybrid Search** - Keyword + semantic for best of both
2. **Source Priority** - Educational content ranked higher
3. **Query Detection** - Adapt search based on intent
4. **Character Normalization** - Handle Chamorro spelling variations
5. **Self-Hosted** - Full control, lower cost at scale

---

## ğŸ”— Related Documentation

- [RAG_MANAGEMENT_GUIDE.md](./RAG_MANAGEMENT_GUIDE.md) - How to add documents
- [RAG_PRIORITY_SYSTEM.md](../docs/RAG_PRIORITY_SYSTEM.md) - Priority tier details
- [SOURCES.md](../docs/SOURCES.md) - Data sources and attribution
- [README.md](../README.md) - Full feature list and setup

---

**Questions?** The code is well-commented - start with `src/rag/chamorro_rag.py`! ğŸŒº



