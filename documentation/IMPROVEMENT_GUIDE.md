# üå∫ H√•faGPT - Development Roadmap

> **Current Status:** Production-ready Chamorro language learning platform with freemium model
> **Last Updated:** December 20, 2025

---

## ‚úÖ Completed Features

All completed features are documented in [`IMPROVEMENT_GUIDE_V1_ARCHIVE.md`](./IMPROVEMENT_GUIDE_V1_ARCHIVE.md).

**Summary of what's built:**
- ü§ñ AI Chat with RAG (45,000+ chunks, DeepSeek V3)
- üí¨ Conversation Practice (7 scenarios)
- üìñ Story Mode (24 stories with tap-to-translate)
- üé¥ Flashcards (curated + dictionary-based)
- üìù Quizzes (curated + dictionary-based, database-tracked)
- üìö Vocabulary Browser (10,350+ words)
- üìÖ Daily Word
- üéÆ Learning Games (Memory Match, Word Scramble, Falling Words, Word Catch, Chamorro Wordle, Hangman, Cultural Trivia)
- üí≥ Freemium Model (Clerk Billing + Stripe)
- üìä Progress Dashboard
- üîê Authentication (Clerk)
- üì± Mobile-optimized responsive design + bottom navigation
- üîß **Admin Dashboard** (User management, analytics, whitelist, ban, settings)
- üéÑ **Seasonal Themes** (Christmas, New Year, Chamorro, Default)
- üéâ **Promo Management** (Admin-controlled promo periods with theme-aware banners)

---

## üéØ Active Roadmap

### **Priority 1: Admin Dashboard** üîß ‚úÖ PHASE 1, 2 & 2.5 COMPLETE

> **Goal:** Web interface to manage users, subscriptions, and content without touching code.

| Phase | Features | Effort | Status |
|-------|----------|--------|--------|
| Phase 1 | User Management + Whitelist | 2-3 sessions | ‚úÖ Complete |
| Phase 1.5 | User Detail + Ban/Actions | 1 session | ‚úÖ Complete |
| Phase 2 | Analytics Dashboard | 1-2 sessions | ‚úÖ Complete |
| Phase 2.5 | Site Settings (Promo + Themes) | 1 session | ‚úÖ Complete |
| Phase 3 | Knowledge Base Management (RAG Upload) | 2-3 sessions | üìã Next |
| Phase 4 | Content Management | 2-3 sessions | ‚è∏Ô∏è Deferred |

#### **Phase 1 + 1.5: User Management** ‚úÖ

**Routes:**
```
/admin                ‚Üí Dashboard overview (stats, quick actions)
/admin/users          ‚Üí User list with search/filter
/admin/users/:id      ‚Üí User detail page with all actions
```

**Completed Features:**
- [x] Admin role check (via `publicMetadata.role`)
- [x] Dashboard stats cards (total users, premium, free, whitelisted, active today)
- [x] Platform activity stats (conversations, messages, quizzes, games)
- [x] User list table with pagination and search
- [x] Mobile-responsive (cards on mobile, table on desktop)
- [x] Click user row to view details
- [x] **User Detail Page** with full profile, stats, actions
- [x] Grant/revoke premium access
- [x] Whitelist users (Friends & Family - permanent free premium)
- [x] **Ban/unban users**
- [x] View user usage stats (all-time + today)
- [x] Admin link in UserButton dropdown (only visible to admins)

**Backend Endpoints:**
```python
GET  /api/admin/stats           # Dashboard overview stats
GET  /api/admin/users           # List users (paginated, searchable)
GET  /api/admin/users/:id       # Get user details + today's usage
PATCH /api/admin/users/:id      # Update user (premium, whitelist, ban, role)
```

**Access Control:**
1. Set admin role in Clerk Dashboard: `{"role": "admin"}`
2. Frontend `AdminRoute` wrapper checks role
3. Backend `verify_admin()` function verifies admin on `/api/admin/*` routes

**To Set Yourself as Admin:**
1. Go to Clerk Dashboard ‚Üí Users ‚Üí Your User
2. Edit **Public metadata** to:
   ```json
   {"role": "admin", "is_premium": true, "is_whitelisted": true}
   ```
3. Refresh your app - you'll see "Admin Dashboard" in the user menu

#### **Phase 2: Analytics Dashboard** ‚úÖ

**Route:** `/admin/analytics`

**Completed Features:**
- [x] Usage trends chart (7d/30d/90d) - chat, games, quizzes per day
- [x] User growth chart - new users per day
- [x] Feature popularity - pie charts for games + quizzes
- [x] Period selector (7 days, 30 days, 90 days)
- [x] Responsive design (stacked on mobile, grid on desktop)

**Not Implemented (future):**
- [ ] Revenue tracking (MRR, subscriptions) - needs Stripe integration
- [ ] Churn tracking - needs subscription history

#### **Phase 2.5: Site Settings (Promo + Themes)** ‚úÖ

**Route:** `/admin/settings`

**Completed Features:**
- [x] `site_settings` database table (key-value store)
- [x] Holiday Promo Management
  - [x] Enable/disable promo toggle
  - [x] Set promo end date
  - [x] Customize banner title
  - [x] Live banner preview
- [x] Theme Switching (Default, Christmas, New Year, Chamorro)
- [x] Theme-aware promo banners (different colors/emojis per theme)
- [x] Christmas snowfall effect (CSS animations)
- [x] Theme-aware logos across app (üå∫ ‚Üî üéÑ)
- [x] Settings caching (60s TTL for performance)

**Backend Endpoints:**
```python
GET  /api/admin/settings       # Get all site settings
PATCH /api/admin/settings      # Update settings (key-value pairs)
GET  /api/promo/status         # Public: Check promo + theme
```

**Database Table:** `site_settings`
```sql
key: 'promo_enabled'     ‚Üí 'true' | 'false'
key: 'promo_end_date'    ‚Üí '2026-01-06'
key: 'promo_title'       ‚Üí 'Felis P√•sgua! ...'
key: 'theme'             ‚Üí 'default' | 'christmas' | 'newyear' | 'chamorro'
```

#### **Phase 3: Knowledge Base Management** üìö (NEW PRIORITY)

> **Goal:** Allow admins to upload documents (PDFs, DOCX, TXT) to expand the RAG knowledge base without touching code. Perfect for school partnerships (e.g., Hurao Chamorro school).

**Route:** `/admin/knowledge-base`

**Planned Features:**
- [ ] Drag & drop file upload (PDF, DOCX, TXT)
- [ ] Background processing with status updates (30s-2min per file)
- [ ] Set source priority (educational, dictionary, archival)
- [ ] List indexed documents with stats
- [ ] View processing status/history
- [ ] Delete documents from RAG (optional)

**Backend Endpoints:**
```python
POST   /api/admin/knowledge-base/upload     # Upload + queue for processing
GET    /api/admin/knowledge-base/status/:id # Check processing status
GET    /api/admin/knowledge-base/documents  # List indexed documents
GET    /api/admin/knowledge-base/stats      # RAG stats (chunks, docs, etc.)
DELETE /api/admin/knowledge-base/:id        # Remove document (optional)
```

**Technical Notes:**
- Leverages existing `RAGDatabaseManager` class
- Docling for PDF processing (handles tables!)
- Token-aware chunking (~350 tokens/chunk)
- OpenAI embeddings for vector storage
- Background task queue for processing

**School Use Case:**
- Teachers upload curriculum PDFs ‚Üí instantly searchable
- Import vocabulary lists and lesson handouts
- Preserve historical Chamorro documents

**Effort:** ~10-14 hours (including background processing)

---

#### **Phase 4: Content Management** (Deferred)

> **Note:** Deferred until there's a clear need. Current curated content is working well and can be edited via git.

**Would require full database migration:**
- [ ] Quiz question CRUD (add/edit/delete questions)
- [ ] Flashcard deck management
- [ ] Story management
- [ ] Game word lists

**Current state:** Content hardcoded in frontend TypeScript files. Works fine for now.

---

### **Priority 2: Chat UX Improvements** üí¨

| Feature | Effort | Status |
|---------|--------|--------|
| Cancel Message | ‚úÖ | Done |
| Response Streaming | ‚úÖ | Done |
| Multi-file Upload | ‚úÖ | Done |
| Optimistic UI | ‚úÖ | Done |
| Smooth Transitions | ‚úÖ | Done |
| Auto-focus Input | ‚úÖ | Done |
| Haptic Feedback | ‚úÖ | Done |
| Sidebar Auto-close | ‚úÖ | Done |
| Background Processing | ‚úÖ | Done |
| Edit & Regenerate | ‚úÖ | Done |
| Parallel Streams | 3-4 hours | üìã Future |

#### **Recently Completed (Dec 2025):**
- **Optimistic UI**: Messages appear instantly, conversation created in background
- **Smooth Transitions**: Loading states when switching conversations
- **Auto-focus**: Input auto-focuses on desktop (not mobile to avoid keyboard)
- **Haptic Feedback**: Vibration on send (mobile devices)
- **Sidebar Auto-close**: Closes when selecting/creating conversations
- **Mobile Input Polish**: Smaller placeholder, compact buttons on mobile
- **Background Processing**: Refetch messages on window focus and page load to catch responses that completed while user was away
- **Edit & Regenerate**: Edit user messages with inline textarea, delete subsequent messages, regenerate AI response with full conversation context

#### **Parallel Streams** (Future)
- Allow multiple conversations to stream responses simultaneously
- Currently: switching conversations cancels in-progress stream
- Future: let streams continue in background, see completed response when returning
- Requires: per-conversation stream tracking, conditional UI updates

---

### **Priority 3: Learning Enhancements** üìö

| Feature | Effort | Status |
|---------|--------|--------|
| Flashcard Spaced Repetition | 2-3 days | üìã Planned |
| Onboarding Flow | 1-2 days | ‚úÖ Done |
| User Preferences | 1 day | ‚úÖ Done |
| Learning Streaks | 2-3 days | ‚úÖ Done |
| Expand Story Content | 1-2 days | üìã Planned |

#### **Onboarding Flow** ‚úÖ
- [x] Skill level selection (Beginner/Intermediate/Advanced)
- [x] Learning goal selection (Conversation, Culture, Family, Travel, Everything)
- [x] Modal appears on first sign-in
- [x] Preferences saved to Clerk `unsafeMetadata`
- [x] AI responses personalized based on skill level

#### **User Preferences Page** ‚úÖ (`/settings`)
- [x] Update skill level and learning goal
- [x] Dark/light mode toggle (syncs across devices)
- [x] Theme preference saved to Clerk profile
- [x] Accessible from user dropdown menu

#### **Admin Preference Management** ‚úÖ
- [x] View user's skill level, learning goal, onboarding status
- [x] Edit user preferences directly
- [x] Reset onboarding (user sees modal again on next login)
- [x] New endpoints: `POST /api/admin/users/:id/reset-onboarding`, `PATCH /api/admin/users/:id/preferences`

#### **Learning Goal Personalization** (Future)
Users select a learning goal during onboarding (conversation, culture, family, travel, or "everything"). Currently this is stored in Clerk's `unsafeMetadata` but **intentionally NOT applied to chat prompts**. 

**Why not use it in chat?** After testing, we found that filtering all responses through a learning goal lens (e.g., always mentioning travel vocabulary) made responses feel forced and could reduce quality when users ask about unrelated topics. The chat should respond naturally to what users actually ask.

**Better uses for learning goals (future):**
- [ ] Personalized homepage recommendations ("Based on your travel goal...")
- [ ] Daily word filtering (show travel vocabulary for travel goal)
- [ ] Suggest relevant flashcard categories
- [ ] Prioritize stories that match the user's goal
- [ ] Adjust conversation practice scenario recommendations
- [ ] Show goal-specific tips and resources

**Note:** The `LEARNING_GOAL_MODIFIERS` dict is defined in `chatbot_service.py` for future reference but is not currently applied.

#### **Flashcard Spaced Repetition (Phase 2)**
- Database tracking for card progress
- Confidence ratings (Hard/Good/Easy)
- "Due for review" scheduling
- Progress indicators

#### **Learning Streaks** ‚úÖ
- [x] Daily streak counter (`/api/streaks/me` endpoint)
- [x] Streak widget on HomePage and Dashboard
- [x] Personal best tracking
- [x] Today's activity breakdown (chat, games, quizzes)
- [x] Guam timezone for day boundaries
- [ ] XP system for activities (future)
- [ ] Achievements/badges (future)
- [ ] Activity calendar (future)

#### **Expand Story Content**
- Add more Lengguahi-ta stories
- Blog content extraction
- Target: 50+ stories

---

### **Priority 4: Performance & Scalability** ‚ö°

> **Goal:** Reduce response latency and prepare for 100+ concurrent users.

#### **Current Infrastructure** ‚úÖ

| Component | Configuration | Status |
|-----------|--------------|--------|
| **Render Plan** | Standard ($25/month) | ‚úÖ 2GB RAM |
| **Gunicorn Workers** | 3 workers | ‚úÖ Parallel requests |
| **Neon Connection Pooling** | PgBouncer via `-pooler` endpoint | ‚úÖ Handles 100+ connections |
| **Cloud Embeddings** | OpenAI (not local) | ‚úÖ Saves 500MB RAM |

**Render Start Command:**
```bash
gunicorn api.main:app -w 3 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:$PORT --timeout 120 --keep-alive 300
```

**Command Breakdown:**

| Flag | Value | Purpose |
|------|-------|---------|
| `api.main:app` | - | Path to FastAPI app (`api/main.py`, variable `app`) |
| `-w` | `3` | Number of worker processes (3 parallel request handlers) |
| `-k` | `uvicorn.workers.UvicornWorker` | Worker class - uses async uvicorn under the hood |
| `--bind` | `0.0.0.0:$PORT` | Listen on all interfaces, Render provides `$PORT` |
| `--timeout` | `120` | Kill worker if request takes >2 min (prevents freezes) |
| `--keep-alive` | `300` | Keep idle connections open for 5 min (for streaming responses) |

**Why 3 workers?**
- Each worker uses ~300-400MB RAM
- 3 workers on 2GB RAM = safe headroom (~1.2GB used)
- More workers = more parallel requests, but diminishing returns
- Rule of thumb: `2 * CPU cores + 1`, but RAM is our constraint

**Neon Connection Pooling:**
- Enabled via Neon dashboard (PgBouncer)
- `DATABASE_URL` uses `-pooler` suffix: `ep-xxx-pooler.us-east-2.aws.neon.tech`
- Handles connection reuse automatically - no app-side pooling needed

**How Gunicorn Workers Differ from Uvicorn:**

| Aspect | Uvicorn (default) | Gunicorn + Uvicorn Workers |
|--------|-------------------|----------------------------|
| **Processes** | 1 process | Multiple processes (we use 3) |
| **Parallelism** | Async I/O only (one thread) | True parallelism (separate CPUs) |
| **Memory** | Shared | Each worker has own memory |
| **Crash Recovery** | App crashes = downtime | One worker crashes, others continue |

**What's shared between workers:**
- ‚úÖ Database (PostgreSQL) - all workers query same DB
- ‚úÖ Freemium limits (`user_daily_usage` table) - stored in DB, works perfectly
- ‚úÖ External APIs (OpenAI, DeepSeek) - stateless calls

**What's NOT shared (in-memory state):**
- ‚ö†Ô∏è IP rate limiting (`rate_limit_storage`) - each worker counts separately
  - Effect: 60 req/min limit becomes ~180 req/min with 3 workers
  - Impact: Minor - still prevents abuse, just less strict
- ‚ö†Ô∏è Message cancellation (`_cancelled_messages` set) - may not cancel if different worker
  - Effect: Rare edge case where cancel doesn't work
  - Impact: Minimal - response still completes, just not cancelled

**Bottom line:** Freemium limits (5 chats/day, etc.) work perfectly. Only anti-abuse rate limiting is slightly relaxed.

---

#### **Remaining Scalability Work**

| Strategy | Effort | Impact | Status |
|----------|--------|--------|--------|
| **Token Tracking (Logging)** | 2-3 hrs | Medium | üìã Planned |
| **Token Warnings** | 1-2 hrs | Low | üìã Planned |
| **Conversation Context Tests** | 3-4 hrs | High | üìã Priority |
| **Response Caching (Redis)** | 4-6 hrs | High | ‚è∏Ô∏è Deferred |
| **Shorter Prompts** | 1-2 hrs | Medium | üìã Planned |
| **Queue System** | 8-12 hrs | Medium | ‚è∏Ô∏è Future |
| **Model Auto-Switching** | 2-3 hrs | Medium | ‚è∏Ô∏è Future |

#### **Token Tracking (Logging)** üìã PLANNED

> **Goal:** Log token usage per conversation for cost monitoring and debugging.

**What it does:**
- Track `prompt_tokens`, `completion_tokens`, `total_tokens` per message
- Store in `conversation_logs` table (new columns)
- Dashboard showing daily/weekly token usage
- Cost estimation based on model pricing

**Why it matters:**
- DeepSeek V3: $0.14/M input, $0.28/M output tokens
- GPT-4o: $2.50/M input, $10.00/M output tokens
- Gemini 2.5 Flash: $0.15/M input, $0.60/M output tokens
- Helps optimize prompts and identify expensive queries

**Implementation:**
```python
# OpenAI/OpenRouter responses include usage
response = client.chat.completions.create(...)
usage = response.usage  # CompletionUsage object
# usage.prompt_tokens, usage.completion_tokens, usage.total_tokens

# Add to conversation_logs table
ALTER TABLE conversation_logs ADD COLUMN prompt_tokens INTEGER;
ALTER TABLE conversation_logs ADD COLUMN completion_tokens INTEGER;
ALTER TABLE conversation_logs ADD COLUMN total_tokens INTEGER;
```

**Effort:** 2-3 hours

#### **Token Warnings** üìã PLANNED (Low Priority)

> **Goal:** Warn when approaching context window limits (128K for DeepSeek V3).

**What it does:**
- Count tokens before sending to LLM
- Warn if approaching 80% of context limit (~100K tokens)
- Optionally truncate old messages to fit
- Log warnings for monitoring

**Why it's low priority:**
- 128K tokens = ~300 pages of text
- Average conversation uses ~5,000-20,000 tokens
- Very few users will ever hit this limit
- Current 10-message history limit keeps us well under

**Implementation (if needed):**
```python
# Use tiktoken for accurate counting
import tiktoken
enc = tiktoken.encoding_for_model("gpt-4")  # Works for most models
token_count = len(enc.encode(full_prompt))

if token_count > 100_000:  # 80% of 128K
    logger.warning(f"Approaching context limit: {token_count} tokens")
    # Optionally truncate oldest messages
```

**Effort:** 1-2 hours

#### **Conversation Context Tests** üìã PRIORITY

> **Goal:** Automated tests to verify the bot maintains context correctly across long conversations.

**What it tests:**
- ‚úÖ Context retention at 5, 10, 20 message depths
- ‚úÖ Reference resolution ("What was that word you mentioned?")
- ‚úÖ No hallucination of past messages
- ‚úÖ Conversation coherence
- ‚úÖ Cross-conversation isolation (no context bleed)

**Test approach:**
```python
# Example test case
conversation_flow = [
    {"user": "How do you say 'hello' in Chamorro?", "check": None},
    {"user": "And how about 'thank you'?", "check": None},
    {"user": "What was the first word I asked about?", "check": ["hello", "h√•fa"]},
    {"user": "Use both words in a sentence", "check": ["h√•fa", "ma'√•se"]},
]
```

**What we caught with these tests:**
- üêõ **FIXED (Dec 2025):** Context was pulling from ALL conversations via `session_id` instead of just the current conversation via `conversation_id`. This caused responses to reference unrelated past conversations!

**File:** `evaluation/test_conversation_context.py`

**Effort:** 3-4 hours

#### **Response Caching (Redis)** ‚è∏Ô∏è DEFERRED

Cache responses for common translation queries. Same question = instant response.

**‚ö†Ô∏è Why Deferred (Dec 2025):**
Caching is best for **mature systems** with stable knowledge bases. We're still:
- Adding new RAG sources (IKNM dictionary, PDFs, etc.)
- Tuning retrieval and prompts
- Improving response quality

**Risks of caching now:**
- ‚ùå Bad response gets cached ‚Üí served to many users repeatedly
- ‚ùå RAG improvements don't reflect in cached responses
- ‚ùå Model upgrades ‚Üí stale cached responses

**When to revisit:**
- Test suite consistently at 95%+ accuracy
- RAG sources are mostly stable (no major additions planned)
- User feedback system in place to catch bad responses

**How it would work (when ready):**
1. Hash the query + mode + skill_level to create a cache key
2. Check Redis/database for cached response before calling LLM
3. Store new responses with short TTL (4-24 hours)
4. Cache invalidation when RAG knowledge base updates
5. Admin cache viewer to manually clear bad responses

**Best candidates for caching:**
- Simple translations: "How do you say 'hello'?" ‚Üí always returns "H√•fa Adai"
- Common phrases: "What is 'thank you' in Chamorro?" ‚Üí always returns "Si Yu'os Ma'√•se'"
- Word of the day queries (already cached separately)

**Not cacheable:**
- Conversations with history context
- Document/image analysis
- Personalized responses (different skill levels may need different caching)

**Effort:** 4-6 hours
**Impact:** 50-70% of translation queries could be instant (when system is mature)

#### **Shorter System Prompts** üìã

Current system prompt is ~800 tokens. Trimming examples and redundant instructions could:
- Reduce latency by 1-2 seconds
- Lower API costs by 20-30%

**Approach:**
1. Audit current prompts for redundancy
2. Move detailed examples to few-shot format
3. A/B test shortened prompts against quality metrics

#### **Queue System** ‚è∏Ô∏è (Future)

For high traffic periods, queue requests instead of failing:
- Redis-based job queue (Bull, Celery)
- "Thinking..." status while queued
- Priority queue for premium users

#### **Model Auto-Switching** ‚è∏Ô∏è (Future)

Automatically switch to faster model during high load:
- DeepSeek V3 (default) ‚Üí GPT-4o-mini (faster, slightly less accurate)
- Based on queue depth or response time metrics

---

### **Priority 5: Homepage & UX Professionalization** üé® üî® IN PROGRESS

> **Goal:** Make H√•faGPT feel as polished and professional as Duolingo/Drops while maintaining our unique value.

**Comparison Notes (Dec 2025):**
- Analyzed Duolingo, LearningChamoru.com, and Drops for best practices
- H√•faGPT has great features but homepage needs clearer hierarchy
- Professional sites have: single clear CTA, minimal cognitive load, mobile-first

#### **Quick Wins (1-2 hours each)** ‚úÖ COMPLETE

| Task | Current | Improvement | Status |
|------|---------|-------------|--------|
| **Simplify Hero Section** | Dual "Explore Free / Free Account" panel | Removed - cleaner flow | ‚úÖ Done |
| **Reduce CTA Clutter** | Multiple "Sign In" buttons, "Account" badges | Removed all badges from cards | ‚úÖ Done |
| **Move "Our Story" to Footer** | Takes header real estate | Now in footer with ‚ù§Ô∏è | ‚úÖ Done |
| **Cleaner Feature Cards** | Many small cards with red badges | Clean, uniform cards | ‚úÖ Done |

#### **Medium Effort (3-5 hours each)**

| Task | Description | Status |
|------|-------------|--------|
| **Mobile Bottom Nav** | Tab bar (Home, Chat, Games, Learn, More) with slide-up menu | ‚úÖ Done |
| **Redesign Homepage Cards** | Fewer, larger feature cards with better visual hierarchy | üìã Planned |
| **Progressive Disclosure** | Don't show all features at once, guide users | üìã Future |

#### **Reference Sites:**
- **Duolingo** ‚Äî Gold standard for gamified learning (minimal CTAs, clear value prop)
- **Drops** ‚Äî Beautiful visual design, mobile-first, bold colors
- **LearningChamoru.com** ‚Äî Structured lessons, dictionary front-and-center

---

### **Future Enhancements** üîÆ

| Feature | Status | Notes |
|---------|--------|-------|
| Quiz TTS (Audio) | üî® In Progress | Read questions and options aloud for accessibility |
| Voice Input | üìã Next | Web Speech API for voice-to-text input |
| Share Conversations | ‚úÖ Done | Shareable public links for conversations |
| Pre-Reader Games | üî® In Progress | Sound Match + Picture Pairs done |
| Homepage Polish | üìã Next | Simplify hero, reduce CTAs, mobile nav |
| LearningChamoru Partnership | ‚è≥ Phase 1 Done | Dictionary sources added, collaboration later |
| New Learning Games (Phase 1) | ‚úÖ Done | Hangman, Cultural Trivia |
| New Learning Games (Phase 2-4) | üìã Planned | Phrase Builder, Speed Challenge, Picture Match, Word Search, Boss Battles, more |
| Admin Settings Polish | ‚úÖ Done | Last Active tracking, Settings quick action, toggle styling |
| Full Offline/Local Mode | ‚è∏Ô∏è Deferred | Needs local LLM setup |
| ElevenLabs Voice Cloning | üìã Future | Better pronunciation |
| PostHog + Stripe Analytics | üìã Future | Revenue correlation |

#### **Voice Input** (Next)
- Add microphone button to chat input
- Use Web Speech API for speech-to-text
- Works on Chrome, Edge, Safari (iOS)
- Fallback message for unsupported browsers
- **Effort:** 2-3 hours

#### **Share Conversations** ‚úÖ COMPLETE
> **Goal:** Generate public shareable links so users can share conversations with friends/family.

**What it does:**
- Click "Share" ‚Üí generates a public link (e.g., `hafagpt.com/share/abc123`)
- Anyone with link can view the conversation (read-only, no auth required)
- Beautiful read-only view with "Try H√•faGPT" CTA for new users

**Backend:**
```python
# New table
shared_conversations (
  id, share_id (uuid), conversation_id, 
  user_id, created_at, expires_at, view_count
)

# New endpoints
POST /api/conversations/:id/share ‚Üí creates share, returns share_id
GET /api/share/:share_id ‚Üí returns conversation (public, no auth)
DELETE /api/share/:share_id ‚Üí revoke share (owner only)
```

**Frontend:**
- New public route: `/share/:shareId` (read-only conversation view)
- Share button in chat header/sidebar
- Copy link modal with success toast
- Optional: expiration settings (24h, 7d, never)

**Effort:** 6-8 hours

#### **Quiz TTS (Audio)** üî® IN PROGRESS

> **Goal:** Add text-to-speech to quizzes for accessibility and young learners.

**What it does:**
- üîä Speaker button reads the question aloud
- üîä Optional: read answer options (for multiple choice)
- üîä Uses existing `useSpeech` hook (OpenAI TTS ‚Üí browser fallback)
- Great for kids who can't read yet, visual impairments, or audio learners

**Implementation:**
- Add `useSpeech` hook to `QuizViewer.tsx`
- Speaker icon next to question text
- Auto-play option in settings (optional future)

**Effort:** 2-3 hours

#### **Pre-Reader Learning Games** üî® IN PROGRESS

> **Goal:** Games that don't require reading, perfect for young children at Hurao Academy.

**Completed:**
- ‚úÖ **Sound Match** ‚Äî Hear word, tap matching emoji. Categories: Animals, Colors, Food, Nature, Numbers.

**Design Principles:**
1. **Audio-first** ‚Äî All instructions spoken, not written
2. **Big touch targets** ‚Äî Large, colorful buttons
3. **Immediate feedback** ‚Äî Sounds/animations for correct/wrong
4. **No text required** ‚Äî Pictures and audio only
5. **Positive reinforcement** ‚Äî Stars, celebrations, no harsh "wrong" sounds

**Planned Games:**

| Game | How It Works | Skills | Status |
|------|--------------|--------|--------|
| **üéµ Sound Match** | Hear a Chamorro word, tap the matching emoji | Listening, vocabulary | ‚úÖ Done |
| **üñºÔ∏è Picture Pairs** | Memory match with emoji pairs (audio on match) | Visual memory, vocabulary | ‚úÖ Done |
| **üé® Color Touch** | "Tap the BLUE one" (Chamorro audio) | Colors, listening | üìã Planned |
| **üî¢ Number Tap** | "Tap 3 coconuts" (Chamorro audio) | Numbers, counting | üìã Planned |
| **üëÜ Simon Says** | "Touch your nose" (Chamorro audio) | Body parts, commands | üìã Planned |

**Next:** Voice Input ‚Äî add speech-to-text for chat.

#### **LearningChamoru.com ‚Äî Learn & Build First (Option A)** üìã IN PROGRESS

> **Strategy:** Learn from their approach quietly, build traction, then explore collaboration later with more leverage.

**About LearningChamoru:**
- Free Chamorro learning platform, 36,000+ registered learners
- Native speaker audio recordings (huge asset!)
- Partnership with University of Guam and CHamoru Language Commission
- 25 structured lessons based on Topping's textbook
- Older web design ‚Äî H√•faGPT's modern UX is a differentiator

**Why We're Complements, Not Competitors:**
| LearningChamoru | H√•faGPT |
|-----------------|---------|
| Structured lessons (25 progressive) | AI chat (ask anything) |
| Native speaker audio | TTS approximation |
| Self-paced modules | Interactive games, quizzes |
| Established (36,000 users) | New, innovative |

**Phase 1: Learn Quietly (Current)** ‚úÖ MOSTLY COMPLETE
- [x] Create account and explore their platform
- [x] Analyze their 25-lesson structure and progression (see `LEARNING_PATH_RESEARCH.md`)
- [ ] Note UX patterns worth adopting (skill levels, community features)
- [x] Check our RAG for Topping's Dictionary/textbook content
- [x] Add LearningChamoru as a resource link in our app (goodwill gesture)
- [x] **Discovered IKNM/KAM Revised Dictionary (2025)** ‚Äî same source they use!

**Phase 1.5: Dictionary Exploration** ‚úÖ COMPLETE (December 2024)
- [x] Found CNMI Revised Dictionary at natibunmarianas.org
- [x] Created custom crawler: `crawlers/iknm_kam_dictionary.py`
- [x] Added 35 chunks (priority 105 - high authority)
- [x] Added Two Chamorro Orthographies PDF (10 chunks)
- [x] Added English-Chamorro Finder List PDF (173 chunks)
- [x] Updated About page with IKNM/KAM credit
- [x] Created `crawlers/SOURCES.md` for tracking

**Phase 2: Build Traction**
- [ ] Get more users (schools like Hurao Academy)
- [ ] Collect testimonials and success stories
- [ ] Establish H√•faGPT as a credible Chamorro learning tool

**Phase 3: Explore Collaboration (Future)**
- [ ] Reach out to Dr. Gerhard Schwab or team
- [ ] Position as complementary (AI chat + their structured lessons)
- [ ] Explore audio licensing, cross-promotion, or integration

**Public Resources We Can Use (With Attribution):**
- ‚úÖ Topping's Dictionary (published reference work)
- ‚úÖ IKNM/KAM Revised Dictionary 2025 (public website)
- ‚úÖ Two Chamorro Orthographies (Dr. Sandra Chung - public PDF)
- ‚úÖ English-Chamorro Finder List 2024 (public PDF)
- ‚úÖ Lesson structure concepts (25-lesson progression is public knowledge)
- ‚úÖ Grammar rules and concepts (not copyrightable)
- ‚ùå Their specific text/audio (need permission)

**Note:** Do NOT scrape their content. Respect their intellectual property. Build relationship before asking for anything.

#### **New Learning Games**

**Phase 1 Complete (Dec 2025):**
- ‚úÖ **Hangman** - Classic word guessing with Chamorro alphabet (√Ö, √ë, ') support
- ‚úÖ **Cultural Trivia** - 30+ questions about Guam culture, history, language, food, and geography

**Phase 2 (Planned - Grammar & Speed):**
| Game | Concept | Learning Value | Effort |
|------|---------|----------------|--------|
| Phrase Builder | Arrange jumbled Chamorro words into correct sentence order | Grammar/word order | 4-5 hrs |
| Speed Challenge | Type translations as fast as possible (60-second race) | Quick recall, typing | 3-4 hrs |

**Phase 3 (Planned - Visual & Relaxing):**
| Game | Concept | Learning Value | Effort |
|------|---------|----------------|--------|
| Picture Match | Match Chamorro words to images | Visual learners, beginners | 6-8 hrs |
| Word Search | Find hidden Chamorro words in a letter grid | Relaxing, word recognition | 6-8 hrs |
| Crossword | Interactive crossword with Chamorro answers | Brain-teaser, spelling | 8-12 hrs |

**Phase 4 (Future - Big Engagement Features):**
| Game | Concept | Learning Value | Effort |
|------|---------|----------------|--------|
| Boss Battles | RPG-style - answer correctly to attack bosses, level up | Gamification, progression | 12-15 hrs |
| Adventure Quest | Story-driven adventure exploring Guam, choose-your-own-path | Narrative, immersion | 15-20 hrs |
| Island Builder | Earn resources by learning, build virtual Guam | Long-term retention | 20+ hrs |
| Multiplayer Showdown | Real-time 1v1 translation battles | Competition, social | 15-20 hrs |

---

## üìÅ Key Documentation

| Document | Purpose |
|----------|---------|
| [`BILLING_AND_SUBSCRIPTIONS.md`](./BILLING_AND_SUBSCRIPTIONS.md) | Freemium model, Clerk Billing, testing |
| [`GAMES_FEATURE.md`](./GAMES_FEATURE.md) | Learning games documentation |
| [`HOW_RAG_WORKS.md`](./HOW_RAG_WORKS.md) | RAG system explanation |
| [`LEARNINGCHAMORU_ANALYSIS.md`](./LEARNINGCHAMORU_ANALYSIS.md) | LearningChamoru.com research & strategy |
| [`LEARNING_PATH_RESEARCH.md`](./LEARNING_PATH_RESEARCH.md) | Topping's lesson structure analysis |
| [`../crawlers/SOURCES.md`](../crawlers/SOURCES.md) | RAG knowledge base source tracking |
| [`IMPROVEMENT_GUIDE_V1_ARCHIVE.md`](./IMPROVEMENT_GUIDE_V1_ARCHIVE.md) | Historical feature documentation |

---

## üí∞ Current Costs

| Service | Cost/Month |
|---------|------------|
| **Render Standard** | $25 |
| Neon PostgreSQL | FREE |
| Clerk (Dev) | FREE |
| DeepSeek V3 | $0.50-2 |
| Gemini 2.5 Flash | $0.05-0.20 |
| OpenAI Embeddings | $0.30 |
| OpenAI TTS HD | $0.50-2 |
| AWS S3 | $0.02-0.10 |
| **Total** | **~$26-30/month** |

> **Note:** Upgraded from Render Starter ($7) to Standard ($25) for 1GB RAM and 2 Gunicorn workers. Database moved from Render PostgreSQL to Neon (free tier with connection pooling).

---

## üéØ Next Steps

1. ‚úÖ ~~Set yourself as admin~~ - Done!
2. ‚úÖ ~~Test Admin Dashboard~~ - Done!
3. ‚úÖ ~~Phase 2: Analytics Dashboard~~ - Done!
4. ‚úÖ ~~Phase 2.5: Site Settings~~ - Done!
5. ‚úÖ ~~Chat UX Improvements~~ - Done!
6. ‚úÖ ~~Edit & Regenerate~~ - Done!
7. ‚úÖ ~~Onboarding Flow~~ - Done!
8. ‚úÖ ~~User Preferences~~ - Done!
9. ‚úÖ ~~Learning Streaks~~ - Done!
10. ‚úÖ ~~Onboarding Feature Overview~~ - Done!
11. ‚úÖ ~~Chat Sidebar Cleanup~~ - Done!
12. ‚úÖ ~~New Games: Hangman + Cultural Trivia~~ - Done!
13. ‚úÖ ~~Admin Settings Polish~~ - Done! (Last Active tracking, Settings quick action, toggle styling)
14. **Voice Input** - Web Speech API for voice-to-text
15. ‚úÖ ~~**Share Conversations**~~ - Done! Public shareable links
16. **New Games Phase 2** - Phrase Builder, Speed Challenge
17. **New Games Phase 3** - Picture Match, Word Search, Crossword

---

## üìä Current Free Tier Limits

| Feature | Free | Premium |
|---------|------|---------|
| Chat messages | 8/day | Unlimited |
| Games | 10/day | Unlimited |
| Quizzes | 5/day | Unlimited |
| Vocabulary | Unlimited | Unlimited |
| Stories | Unlimited | Unlimited |

---

**Admin Dashboard Phase 1, 2 & 2.5 Complete! üéÑ**

User management + analytics + site settings all working!

---

## üêõ Recent Bug Fixes & Improvements

### December 20, 2025 - Stability & Reliability Overhaul

> **Context:** Production usage revealed critical issues with token overflow, message persistence, and database connection stability. This release addresses all issues with proper fixes (not bandaids).

| Category | Issue | Root Cause | Fix |
|----------|-------|------------|-----|
| **üö® Token Overflow** | `prompt length (113440) exceeds max_num_tokens (32768)` errors | No token limits - conversations could grow unbounded, RAG could add unlimited context | Created `token_manager.py` with 24K token budget, truncation for system prompt, RAG context, conversation history, and current message |
| **üö® Messages Lost** | User messages disappeared after connection errors | `log_conversation` only called after successful LLM response | Now save messages even when errors occur (with error indicator) |
| **üö® Database Drops** | `SSL connection has been closed unexpectedly` errors | Neon serverless PostgreSQL drops idle connections | Added `_get_db_connection_with_retry()` with exponential backoff in both `chatbot_service.py` and `chamorro_rag.py` |
| **üö® RAG Retry Bug** | SSL errors in RAG weren't retried | Connection errors were caught and swallowed instead of bubbling up to retry wrapper | Modified error handlers to re-raise connection errors for retry |
| **‚ö†Ô∏è PWA Stale Cache** | Some updates visible, others not (e.g., bottom nav but no edit button) | `skipWaiting()` called automatically, unpredictable update timing | PWA update notification banner with user-controlled updates |
| **‚ö†Ô∏è Pre-promo Premium** | Users who signed up before promo didn't show as premium | Frontend only checked `is_premium` metadata, not promo status | `isPremium = status.is_premium \|\| isPromoActive` in `useSubscription.ts` |
| **üìä Monitoring** | No visibility into production errors | No error tracking | Added Sentry SDK integration with FastAPI, request context, token overflow tracking |

**New Files:**
- `src/utils/token_manager.py` - Token counting, budget management, truncation, summarization
- `src/utils/sentry_config.py` - Sentry error tracking configuration
- `evaluation/test_stress.py` - Stress tests for token management (15K token messages, 25-turn conversations)
- `src/hooks/usePWAUpdate.ts` - PWA update detection hook
- `src/components/PWAUpdateBanner.tsx` - User notification for new versions

**Token Budget (24K total):**
| Component | Max Tokens |
|-----------|------------|
| System Prompt | 3,000 |
| RAG Context | 4,000 |
| Conversation History | 8,000 |
| Current Message | 6,000 |
| Response Buffer | 3,000 |

**Stress Test Results (All Passed):**
- ‚úÖ Error Recovery - Empty/edge case messages handled gracefully
- ‚úÖ Rapid Fire (10/10) - Quick successive requests all succeeded
- ‚úÖ Long Message (15K tokens) - Truncated and processed in 39s
- ‚úÖ Many Turns (25 messages) - All turns succeeded, avg 21s response
- ‚úÖ Combined Stress (15 turns + 8K message) - Processed in 25s

### December 16, 2025
| Fix | Description |
|-----|-------------|
| **üö® Conversation Context Bleed** | **CRITICAL FIX:** Chat history was using `session_id` (browser-based) instead of `conversation_id`, causing responses to reference unrelated past conversations. Now each conversation has isolated context. |

### December 13, 2025
| Change | Description |
|--------|-------------|
| **User Settings Page** | New `/settings` page to update skill level, learning goal, and theme |
| **Onboarding Modal** | First-time users select skill level and learning goal |
| **AI Personalization** | Responses adapt based on user's skill level (beginner/intermediate/advanced) |
| **Theme Sync** | Dark/light mode preference syncs across devices via Clerk |
| **Admin Preference Management** | View/edit user preferences, reset onboarding from admin panel |
| **Admin Settings** | New page for promo and theme management (`/admin/settings`) |
| **Christmas Theme** | Snowfall animation, festive logos, theme-aware banners |
| **Promo Management** | Admin-controlled promo periods (no more env vars needed) |
| **Chat UX Polish** | Optimistic UI, smooth transitions, haptic feedback |
| **Mobile Input** | Compact placeholder, responsive buttons |
| **Background Processing** | Messages refetch on window focus/page load to catch background completions |
| **Stream Cancellation** | Switching conversations cleanly cancels in-progress streams |
| **Edit & Regenerate** | Edit user messages inline, regenerate AI response with full history context |

### December 10, 2025
| Fix | Description |
|-----|-------------|
| **Word of the Day filtering** | Added safe category filtering + blocklist to ensure family-friendly vocabulary (no inappropriate words) |
| **RAG connection stability** | Added retry logic for database connections to handle Neon serverless cold starts and SSL drops |
| **Icon centering** | Fixed off-centered icons for theme toggles and speak buttons across all pages |

