#!/bin/bash

# Test crawl for Lengguahi-ta - 10 Pages
# This will crawl ~10 pages to verify data quality and formatting.

echo "ğŸ§ª Lengguahi-ta Test Crawl - 10 Pages"
echo "======================================="
echo ""
echo "â±ï¸  Estimated time: 1-2 minutes"
echo "ğŸ“„ Pages: ~10"
echo "ğŸ’° Cost: \$0 (local HuggingFace embeddings)"
echo ""
echo "âš ï¸  Ensure your .env DATABASE_URL points to your production Neon DB!"
echo ""

read -p "Press Enter to start the test crawl, or Ctrl+C to cancel..."

cd "$(dirname "$0")" # Change to script directory

cd "$(dirname "$0")/../.." && uv run python src/crawlers/crawl_lengguahita.py \
  --max-depth 2 \
  --max-pages 10 \
  --same-domain-only

echo ""
echo "âœ… Test crawl complete!"
echo ""
echo "ğŸ“Š Review the results:"
echo "  1. Check the terminal output - verify URLs crawled"
echo "  2. Confirm content looks clean (no navigation junk)"
echo "  3. Check chunk counts are reasonable"
echo ""
echo "âœ¨ If it looks good, run the full crawl:"
echo "  ./crawl_lengguahita.sh"
echo ""

