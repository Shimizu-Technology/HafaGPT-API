[project]
name = "llm-project"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "alembic>=1.17.2",
    "boto3>=1.40.74",
    "chromadb>=1.3.4",
    "clerk-backend-api>=4.0.0",
    "crawl4ai>=0.4.0",
    "fastapi>=0.115.0",
    "langchain>=1.0.5",
    "langchain-chroma>=1.0.0",
    "langchain-community>=0.4.1",
    # REMOVED: langchain-huggingface (900MB+ with torch/transformers)
    # We use langchain-openai for cloud embeddings (tiny memory footprint)
    "langchain-openai>=0.3.12",
    "langchain-postgres>=0.0.16",
    "openai>=2.7.1",
    "psycopg2-binary>=2.9.11",
    "psycopg[binary]>=3.2.3",
    "pypdf>=5.0.0",  # PDF text extraction (lightweight, no Java)
    "python-docx>=1.1.0",  # Word document parsing
    "python-dotenv>=1.2.1",
    "python-jose[cryptography]>=3.5.0",
    "python-multipart>=0.0.20",
    "requests>=2.32.3",
    # REMOVED: sentence-transformers (500MB+, only needed for local embeddings)
    "uvicorn>=0.34.0",
    # Model comparison dependencies
    "httpx>=0.27.0",  # For OpenRouter API client
    # Webhook verification
    "svix>=1.17.0",  # Clerk uses Svix for webhooks
    "gunicorn>=23.0.0",
    "pypdf2>=3.0.1",
    "tiktoken>=0.12.0",
    "sentry-sdk>=2.48.0",
]

# Optional dependencies for direct API access (instead of OpenRouter)
[project.optional-dependencies]
model-comparison = [
    "anthropic>=0.39.0",  # Direct Claude API
    "google-generativeai>=0.8.0",  # Direct Gemini API
]

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["."]
include = ["api*", "crawlers*"]
namespaces = false
